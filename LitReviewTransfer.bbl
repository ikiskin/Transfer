\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{anandconvoluted}
Anand, N., Verma, P.: Convoluted feelings convolutional and recurrent nets for
  detecting emotion from audio data

\bibitem{bishop2006pattern}
Bishop, C.M.: Pattern recognition. Machine Learning  128,  1--58 (2006)

\bibitem{dahl2013improving}
Dahl, G.E., Sainath, T.N., Hinton, G.E.: Improving deep neural networks for
  lvcsr using rectified linear units and dropout. In: Acoustics, Speech and
  Signal Processing (ICASSP), 2013 IEEE International Conference on. pp.
  8609--8613. IEEE (2013)

\bibitem{dahl2012context}
Dahl, G.E., Yu, D., Deng, L., Acero, A.: Context-dependent pre-trained deep
  neural networks for large-vocabulary speech recognition. IEEE Transactions on
  Audio, Speech, and Language Processing  20(1),  30--42 (2012)

\bibitem{deng2014achievements}
Deng, L.: Achievements and challenges of deep learningâ€”from speech analysis
  and recognition to language and multimodal processing. In: Fifteenth Annual
  Conference of the International Speech Communication Association (2014)

\bibitem{dieleman2014end}
Dieleman, S., Schrauwen, B.: End-to-end learning for music audio. In: 2014 IEEE
  International Conference on Acoustics, Speech and Signal Processing (ICASSP).
  pp. 6964--6968. IEEE (2014)

\bibitem{espi2015exploiting}
Espi, M., Fujimoto, M., Kinoshita, K., Nakatani, T.: Exploiting
  spectro-temporal locality in deep learning based acoustic event detection.
  EURASIP Journal on Audio, Speech, and Music Processing  2015(1), ~1 (2015)

\bibitem{giannoulis2013detection}
Giannoulis, D., Benetos, E., Stowell, D., Rossignol, M., Lagrange, M.,
  Plumbley, M.D.: Detection and classification of acoustic scenes and events:
  An ieee aasp challenge. In: Applications of Signal Processing to Audio and
  Acoustics (WASPAA), 2013 IEEE Workshop on. pp. 1--4. IEEE (2013)

\bibitem{goeau2015lifeclef}
Go{\"e}au, H., Glotin, H., Vellinga, W.P., Planqu{\'e}, R., Rauber, A., Joly,
  A.: {LifeCLEF} bird identification task 2015. In: CLEF2015 (2015)

\bibitem{gwardys2014deep}
Gwardys, G., Grzywczak, D.: Deep image features in music information retrieval.
  International Journal of Electronics and Telecommunications  60(4),  321--326
  (2014)

\bibitem{humphrey2013feature}
Humphrey, E.J., Bello, J.P., LeCun, Y.: Feature learning and deep
  architectures: new directions for music informatics. Journal of Intelligent
  Information Systems  41(3),  461--481 (2013)

\bibitem{humphrey2011non}
Humphrey, E.J., Glennon, A.P., Bello, J.P.: Non-linear semantic embedding for
  organizing large instrument sample libraries. In: Machine Learning and
  Applications and Workshops (ICMLA), 2011 10th International Conference on.
  vol.~2, pp. 142--147. IEEE (2011)

\bibitem{joly2016lifeclef}
Joly, A., Go{\"e}au, H., Glotin, H., Spampinato, C., Bonnet, P., Vellinga,
  W.P., Champ, J., Planqu{\'e}, R., Palazzo, S., M{\"u}ller, H.: {LifeCLEF}
  2016: multimedia life species identification challenges. In: International
  Conference of the Cross-Language Evaluation Forum for European Languages. pp.
  286--310. Springer (2016)

\bibitem{juang2005automatic}
Juang, B.H., Rabiner, L.R.: Automatic speech recognition--a brief history of
  the technology development. Georgia Institute of Technology. Atlanta Rutgers
  University and the University of California. Santa Barbara  1, ~67 (2005)

\bibitem{mcvicar2016learning}
McVicar, M., Santos-Rodr, R., De~Bie, T., et~al.: Learning to separate vocals
  from polyphonic mixtures via ensemble methods and structured output
  prediction. In: 2016 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP). pp. 450--454. IEEE (2016)

\bibitem{mirex2016}
MIREX: 2016 results (2016),
  \url{http://www.music-ir.org/mirex/results/2016/mirex_2016_poster.pdf},
  accessed: 2017-04-07

\bibitem{mirex2016chord}
MIREX: 2016 results (2016),
  \url{http://www.music-ir.org/mirex/abstracts/2016/FK2.pdf}, accessed:
  2017-04-07

\bibitem{mohamed2012acoustic}
Mohamed, A.r., Dahl, G.E., Hinton, G.: Acoustic modeling using deep belief
  networks. IEEE Transactions on Audio, Speech, and Language Processing  20(1),
   14--22 (2012)

\bibitem{mostefa2007chil}
Mostefa, D., Moreau, N., Choukri, K., Potamianos, G., Chu, S.M., Tyagi, A.,
  Casas, J.R., Turmo, J., Cristoforetti, L., Tobia, F., et~al.: The chil
  audiovisual corpus for lecture and meeting analysis inside smart rooms.
  Language Resources and Evaluation  41(3-4),  389--407 (2007)

\bibitem{van2016wavenet}
van~den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A.,
  Kalchbrenner, N., Senior, A., Kavukcuoglu, K.: Wavenet: A generative model
  for raw audio. CoRR abs/1609.03499  (2016)

\bibitem{phan2016robust}
Phan, H., Hertel, L., Maass, M., Mertins, A.: Robust audio event recognition
  with 1-max pooling convolutional neural networks. arXiv preprint
  arXiv:1604.06338  (2016)

\bibitem{potamitis2016deep}
Potamitis, I.: Deep learning for detection of bird vocalisations. arXiv
  preprint arXiv:1609.08408  (2016)

\bibitem{rabiner1993fundamentals}
Rabiner, L.R., Juang, B.H.: Fundamentals of speech recognition  (1993)

\bibitem{sainath2015deep}
Sainath, T.N., Kingsbury, B., Saon, G., Soltau, H., Mohamed, A.r., Dahl, G.,
  Ramabhadran, B.: Deep convolutional neural networks for large-scale speech
  tasks. Neural Networks  64,  39--48 (2015)

\bibitem{sprengel2016audio}
Sprengel, E., Martin~Jaggi, Y., Hofmann, T.: Audio based bird species
  identification using deep learning techniques. Working notes of CLEF  (2016)

\bibitem{wilson2016deep}
Wilson, A.G., Hu, Z., Salakhutdinov, R., Xing, E.P.: Deep kernel learning. In:
  Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics. pp. 370--378 (2016)

\end{thebibliography}
